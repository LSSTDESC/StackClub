{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Access with the Gen-2 Butler\n",
    "\n",
    "<br>Owner: **Daniel Perrefort** ([@djperrefort](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@djperrefort))\n",
    "<br>Last Verified to Run: **2020-07-17**\n",
    "<br>Verified Stack Release: **v20.0.0**\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "This notebook provides a hands-on overview of how to interact with the Gen-2 `Butler` (it should be updated for Gen-3, once available). The `Butler` provides a way to access information using a uniform interface without needing to keep track of how the information is internally stored or organized. Data access with `Butler` has three levels you need to be aware of:\n",
    "\n",
    "1. Each instantiated `Butler` object provides access to a collection of datasets called a **repository**. Each repository is defined by Butler using the local file directory where the data is stored.\n",
    "2. Each data set in a **repository** is assigned a unique name called a **type**. These types are strings that describe the data set and should not be confused with an \"object type\" as defined by Python.\n",
    "3. Individual entries in a data set are identified using a unique **data identifier**, which is a dictionary who's allowed keys and values depend on the data set you are working with.\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "This notebook demonstrates how to use the Gen-2 `Butler` object from the DM stack to access and manipulate data. After finishing this notebook, users will know how to:\n",
    "\n",
    "1. Load and access a data repository using `Butler`\n",
    "2. Select subsets of data and convert data into familiar data structures\n",
    "3. Use `Butler` to access coordinate information and cutout postage stamps\n",
    "4. Use `Butler` to access a skymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.daf.persistence import Butler\n",
    "import lsst.geom\n",
    "from lsst.geom import SpherePoint, Angle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "To start we instantiate a `Butler` object by providing it with the directory of the **repository** we want to access. Next, we load a **type** of dataset and select data from a single **data identifier**. For this demonstration we consider the `deepCoadd_ref` dataset, which contains tables of information concerning coadded images used in the differencing image pipeline. The id values for this data set include two required values: `tract` and `patch` which denote sections of the sky.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = '/project/shared/data/DATA_ci_hsc/rerun/coaddForcedPhot'\n",
    "butler = Butler(repo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose an \"arbitrary\" tract and patch. \n",
    "# Want to figure out how we found this tract and patch? Check out the notebook on Exploring_A_Data_Repo.ipynb\n",
    "data_id = {'tract': 0, 'patch': '1,1'}\n",
    "dataset_type = 'deepCoadd_ref'\n",
    "\n",
    "# We can check that the data exists before we try to read it\n",
    "data_exists = butler.datasetExists(datasetType=dataset_type, dataId=data_id)\n",
    "print('Data exists for ID:', data_exists)\n",
    "\n",
    "data_entry = butler.get(dataset_type, dataId=data_id)\n",
    "data_entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data table returned above is formatted as a `SourceCatalog` object, which is essentially a collection of `numpy` arrays. We can see this when we index a particular column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data_entry['merge_measurement_i']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SourceCatalog` objects have their own set of methods for table manipulations (sorting, appending rows, etc.). However, we can also work with the data in a more familiar format, such as an astropy `Table` or a pandas `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_entry.asAstropy().to_pandas()\n",
    "data_frame.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that `Butler` objects do not always return tabular data. We will see an example of this later when we load and parse image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Subsets of Data\n",
    "\n",
    "In practice, you may not know the format of the data identifier for a given data set. In this case, the `getKeys()` method can be used to determine the key values expected in a **data identifier**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id_format = butler.getKeys(dataset_type)\n",
    "print('Expected data id format:', data_id_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that if you specify a key that is not part of the data **type**, the `Butler` will silently ignore it. This can be misleading. For example, in the previous example we read in a table that has a column of booleans named `merge_footprint_i`. If you specify `merge_footprint_i: True` in the dataID and rerun the example, `Butler` will ignore the extra key silently. As a result, you might expect the returned table to only include values where `merge_footprint_i` is `True`, but that isn't what happens. \n",
    "\n",
    "Here is an example of the correct way to select data from the returned table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of what not to do!!\n",
    "#\n",
    "# new_data_id = {'tract': 0, 'patch': '1,1', 'merge_footprint_i': True}\n",
    "# merged_i_data = butler.get(dataset_type, dataId=new_data_id)\n",
    "# assert merged_i_data['merge_measurement_i'].all()\n",
    "\n",
    "# Do this instead...\n",
    "new_data_id = {'tract': 0, 'patch': '1,1'}\n",
    "merged_i_data = butler.get(dataset_type, dataId=new_data_id)\n",
    "merged_i_data = merged_i_data[merged_i_data['merge_measurement_i']].copy(True)\n",
    "\n",
    "# Check that the returned table does in fact have only entries where\n",
    "# merge_footprint_i is True\n",
    "print(merged_i_data['merge_measurement_i'].all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:**  Note the use of `copy` above which is required to create an array that is contiguous in memory (yay!)\n",
    "\n",
    "You can also select all complete dataIds for a dataset type that match a partial (or empty) dataId. For example, the below cell iterates over all possible ids and checks if the corresponding file exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = butler.subset(dataset_type, dataId=data_id)\n",
    "id_list = [dr.dataId for dr in subset if dr.datasetExists()]\n",
    "print(f'Available Ids:\\n {id_list}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Postage Stamps\n",
    "\n",
    "When dealing with image data, we can use `Butler` to generate postage stamps at a given set of coordinates. For this example, we consider the `deepCoadd` data set, which has one extra key value than the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coadd_type = 'deepCoadd'\n",
    "butler.getKeys(coadd_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a postage stamp, we need to define the center and size of the cutout. First, we pick an RA and Dec from our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of all targets with a flux between 100 and 500 as follows\n",
    "# np.where((merged_i_data['base_PsfFlux_flux'] > 100) & (merged_i_data['base_PsfFlux_flux'] < 500))\n",
    "\n",
    "# Pick an RA and Dec\n",
    "i = 1000\n",
    "ra =  np.degrees(merged_i_data['coord_ra'][i])\n",
    "dec = np.degrees(merged_i_data['coord_dec'][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot our cutout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the image using butler\n",
    "coadd_id = {'tract': 0, 'patch': '1,1', 'filter': 'HSC-I'}\n",
    "image = butler.get(coadd_type, dataId=coadd_id)\n",
    "\n",
    "# Define the center and size of our cutout\n",
    "radec = SpherePoint(ra, dec, lsst.geom.degrees)\n",
    "cutout_size = 150\n",
    "cutout_extent = lsst.geom.ExtentI(cutout_size, cutout_size)\n",
    "\n",
    "# Cutout and optionally save the postage stamp to file\n",
    "postage_stamp = image.getCutout(radec, cutout_extent)\n",
    "# postage_stamp.writeFits(<output_filename>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the postage stamp was generated using `Butler`, it is represented as an `afwImage` object. This is a data type from the DM stack that is used to represent images. Since it is a DM object, we choose to plot it using the DM `afwDisplay` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = postage_stamp.getWcs().skyToPixel(radec)\n",
    "\n",
    "display = afwDisplay.Display(frame=1, backend='matplotlib')\n",
    "display.mtv(postage_stamp)\n",
    "display.scale(\"linear\", \"zscale\")\n",
    "display.dot('o', xy.getX(), xy.getY(), ctype='red')\n",
    "display.show_colorbar()\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cutout image is aware of the masks and pixel values of the original image. This is why the axis labels in the above cutout are so large. We also note that the orientation of the postage stamp is in the x, y orientation of the original coadded image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting an Area on the Sky with a Sky Map\n",
    "\n",
    "As a final example, we consider a third type of data that can be accessed via `Butler` called a `skyMap`. Sky maps allow you to look up information for a given `tract` and `patch`. You may notice from the below example that data set **types** tend to follow the naming convention of having a base name (e.g. `'deepCoadd'`) followed by a descriptor (e.g. `'_skyMap'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = butler.get('deepCoadd_skyMap')\n",
    "tract_info = skymap[0]\n",
    "tract_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_info = tract_info.getPatchInfo((1,1))\n",
    "patch_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_bbox = tract_info.getBBox()\n",
    "tract_pix_corners = lsst.geom.Box2D(tract_bbox).getCorners()\n",
    "print('Tract corners in pixels:\\n', tract_pix_corners)\n",
    "\n",
    "wcs = tract_info.getWcs()\n",
    "tract_deg_corners = wcs.pixelToSky(tract_pix_corners)\n",
    "tract_deg_corners = [[c.getRa().asDegrees(), c.getDec().asDegrees()] for c in tract_deg_corners]\n",
    "print('\\nTract corners in degrees:\\n', tract_deg_corners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also go in reverse to find the tract, patch that contains a coordinate (320.8,-0.4)\n",
    "coordList = [SpherePoint(Angle(np.radians(320.8)),Angle(np.radians(-0.4)))]\n",
    "tractInfo = skymap.findClosestTractPatchList(coordList)\n",
    "print(tractInfo[0][0])\n",
    "print(tractInfo[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
