{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblending with *Scarlet*\n",
    "<br>Owner(s): **Fred Moolekamp** ([@fred3m](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@fred3m))\n",
    "<br>Last Verified to Run: **2019-08-16**\n",
    "<br>Verified Stack Release: **w_2019-31**\n",
    "\n",
    "The purpose of this tutorial is to familiarize you with the basics of using *scarlet* to model blended scenes, and how tweaking various objects and parameters affects the resulting model. A tutorial that is more specific to using scarlet in the context of the LSST DM Science Pipelines is also available.\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "After working through this tutorial you should be able to: \n",
    "1. Configure and run _scarlet_ on a test list of objects;\n",
    "2. Understand its various model assumptions and applied constraints.\n",
    "\n",
    "Before attempting this tutorial it will be useful to read the [introduction](https://fred3m.github.io/scarlet/user_docs.html) to the *scarlet* User Guide, and many of the exercises below may require referencing the *scarlet* [docs](https://fred3m.github.io/scarlet/).\n",
    "\n",
    "### Logistics\n",
    "This notebook is intended to be runnable on `lsst-lsp-stable.ncsa.illinois.edu` from a local git clone of https://github.com/LSSTScienceCollaborations/StackClub.\n",
    "\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of the Stack are we using?\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping\n",
    "\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display functions\n",
    "\n",
    "Below are several useful functions used throughout this tutorial to visualize the data and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sources\n",
    "# Display the sources\n",
    "def display_sources(sources, observation, norm=None, subset=None, combine=False, show_sed=True):\n",
    "    \"\"\"Display the data and model for all sources in a blend\n",
    "\n",
    "    This convenience function is used to display all (or a subset) of\n",
    "    the sources and (optionally) their SED's.\n",
    "    \"\"\"\n",
    "    if subset is None:\n",
    "        # Show all sources in the blend\n",
    "        subset = range(len(sources))\n",
    "    for m in subset:\n",
    "        # Load the model for the source\n",
    "        src = sources[m]\n",
    "        if hasattr(src, \"components\"):\n",
    "            components = len(src.components)\n",
    "        else:\n",
    "            components = 1\n",
    "        # Convolve the model with the psfs in the observation\n",
    "        model = observation.render(src.get_model())\n",
    "        # Extract the bounding box that contains the non-zero\n",
    "        # pixels in the model\n",
    "        bbox = scarlet.bbox.trim(np.sum(model, axis=0), min_value=1e-2)\n",
    "        bb = (slice(None), *bbox.slices)\n",
    "        # Adjust the stretch based on the maximum flux in the model for the current source\n",
    "        if model.max() > 10 * bg_rms.max():\n",
    "            norm = AsinhMapping(minimum=model.min(), stretch=model.max()*.05, Q=10)\n",
    "        else:\n",
    "            norm = LinearMapping(minimum=model.min(), maximum=model.max())\n",
    "\n",
    "        # Select the image patch the overlaps with the source and convert it to an RGB image\n",
    "        img_rgb = scarlet.display.img_to_rgb(images[bb], norm=norm)\n",
    "\n",
    "        # Build a model for each component in the model\n",
    "        if hasattr(src, \"components\"):\n",
    "            rgb = []\n",
    "            for component in src.components:\n",
    "                # Convert the model to an RGB image\n",
    "                _model = observation.get_model(component.get_model())\n",
    "                _rgb = scarlet.display.img_to_rgb(_model[bb], norm=norm)\n",
    "                rgb.append(_rgb)\n",
    "        else:\n",
    "            # There is only a single component\n",
    "            rgb = [scarlet.display.img_to_rgb(model[bb], norm=norm)]\n",
    "\n",
    "        # Display the image and model\n",
    "        figsize = [6,3]\n",
    "        columns = 2\n",
    "        # Calculate the number of columns needed and shape of the figure\n",
    "        if show_sed:\n",
    "            figsize[0] += 3\n",
    "            columns += 1\n",
    "        if not combine:\n",
    "            figsize[0] += 3*(components-1)\n",
    "            columns += components-1\n",
    "        # Build the figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = [fig.add_subplot(1,columns,n+1) for n in range(columns)]\n",
    "        ax[0].imshow(img_rgb)\n",
    "        ax[0].set_title(\"Data: Source {0}\".format(m))\n",
    "        for n, _rgb in enumerate(rgb):\n",
    "            ax[n+1].imshow(_rgb)\n",
    "            if combine:\n",
    "                ax[n+1].set_title(\"Initial Model\")\n",
    "            else:\n",
    "                ax[n+1].set_title(\"Component {0}\".format(n))\n",
    "        if show_sed:\n",
    "            if components > 1:\n",
    "                for comp in src:\n",
    "                    ax[-1].plot(comp.sed)\n",
    "            else:\n",
    "                ax[-1].plot(src.sed)\n",
    "            ax[-1].set_title(\"SED\")\n",
    "            ax[-1].set_xlabel(\"Band\")\n",
    "            ax[-1].set_ylabel(\"Intensity\")\n",
    "        # Mark the current source in the image\n",
    "        if components > 1:\n",
    "            y,x = src.components[0].pixel_center\n",
    "        else:\n",
    "            y,x = src.pixel_center\n",
    "        ax[0].plot(x-bb[2].start, y-bb[1].start, 'rx', mew=2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def display_model_residual(images, blend, peaks, norm):\n",
    "    \"\"\"Display the data, model, and residual for a given result\n",
    "    \"\"\"\n",
    "    model = blend.get_model()\n",
    "    residual = images-model\n",
    "    print(\"Data range: {0:.3f} to {1:.3f}\\nresidual range: {2:.3f} to {3:.3f}\\nrms: {4:.3f}\".format(\n",
    "        np.min(images),\n",
    "        np.max(images),\n",
    "        np.min(residual),\n",
    "        np.max(residual),\n",
    "        np.sqrt(np.std(residual)**2+np.mean(residual)**2)\n",
    "    ))\n",
    "    # Create RGB images\n",
    "    img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "    model_rgb = scarlet.display.img_to_rgb(model, norm=norm)\n",
    "    residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "    # Show the data, model, and residual\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "    ax[0].imshow(img_rgb)\n",
    "    ax[0].set_title(\"Data\")\n",
    "    ax[1].imshow(model_rgb)\n",
    "    ax[1].set_title(\"Model\")\n",
    "    ax[2].imshow(residual_rgb)\n",
    "    ax[2].set_title(\"Residual\")\n",
    "    for k,component in enumerate(blend.components):\n",
    "        y,x = component.pixel_center\n",
    "        #px, py = peaks[k]\n",
    "        ax[0].plot(x, y, \"gx\")\n",
    "        #ax[0].plot(px, py, \"rx\")\n",
    "        ax[1].text(x, y, k, color=\"r\")\n",
    "    plt.show()\n",
    "\n",
    "def show_psfs(psfs, filters, norm=None):\n",
    "    rows = int(np.ceil(len(psfs)/3))\n",
    "    columns = min(len(psfs), 3)\n",
    "    figsize = (45/columns, rows*5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = [fig.add_subplot(rows, columns, n+1) for n in range(len(psfs))]\n",
    "    for n, psf in enumerate(psfs):\n",
    "        im = ax[n].imshow(psf, norm=norm)\n",
    "        ax[n].set_title(\"{0}-band PSF\".format(filters[n]))\n",
    "        plt.colorbar(im, ax=ax[n])\n",
    "    plt.show()\n",
    "\n",
    "def display_diff_kernels(psf_blend, diff_kernels):\n",
    "    model = psf_blend.get_model()\n",
    "    for b, component in enumerate(psf_blend.components):\n",
    "        fig = plt.figure(figsize=(15,2.5))\n",
    "        ax = [fig.add_subplot(1,4,n+1) for n in range(4)]\n",
    "        # Display the psf\n",
    "        ax[0].set_title(\"psf\")\n",
    "        _img = ax[0].imshow(psfs[b])\n",
    "        fig.colorbar(_img, ax=ax[0])\n",
    "        # Display the model\n",
    "        ax[1].set_title(\"modeled psf\")\n",
    "        _model = np.ma.array(model[b], mask=model[b]==0)\n",
    "        _img = ax[1].imshow(_model)\n",
    "        fig.colorbar(_img, ax=ax[1])\n",
    "        # Display the difference kernel\n",
    "        ax[2].set_title(\"difference kernel\")\n",
    "        _img = ax[2].imshow(np.ma.array(diff_kernels[b], mask=diff_kernels[b]==0))\n",
    "        fig.colorbar(_img, ax=ax[2])\n",
    "        # Display the residual\n",
    "        ax[3].set_title(\"residual\")\n",
    "        residual = psfs[b]-model[b]\n",
    "        vabs = np.max(np.abs(residual))\n",
    "        _img = ax[3].imshow(residual, vmin=-vabs, vmax=vabs, cmap='seismic')\n",
    "        fig.colorbar(_img, ax=ax[3])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Display the data\n",
    "\n",
    "The `file_path` points to a directory with 147 HSC blends from the COSMOS field detected by the LSST pipeline. Changing `idx` below will select a different blend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "idx = 53\n",
    "file_path = \"/project/shared/data/testdata_deblender/real_data/hsc_cosmos/not_matched\"\n",
    "files = os.listdir(file_path)\n",
    "data = np.load(os.path.join(file_path, files[idx]))\n",
    "images = data[\"images\"]\n",
    "weights = data[\"weights\"]\n",
    "peaks = data[\"peaks\"]\n",
    "psfs = data[\"psfs\"]\n",
    "filters = [\"G\", \"R\", \"I\", \"Z\", \"Y\"]\n",
    "# Only a rough estimate of the background is needed\n",
    "# to initialize and resize the sources\n",
    "bg_rms = np.std(images, axis=(1,2))\n",
    "print(\"Background RMS: {0}\".format(bg_rms))\n",
    "\n",
    "# Use Asinh scaling for the images\n",
    "norm = AsinhMapping(minimum=images.min(), stretch=images.max()/20, Q=10)\n",
    "# Convert the image to an RGB image\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Image: {0}\".format(idx))\n",
    "for k, src in enumerate(peaks):\n",
    "    plt.text(src[0], src[1], str(k), color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model and observation frames\n",
    "\n",
    "A `Frame` in scarlet is the metadata that defines the hyperspectral data cube, including dimensions, wcs (optional), and the PSF (technically optional but recommended). So we need to define a frame for our model and for the `Observation`, which contains the image and variance data for the observations of the scene that we are deblending. In scarlet it is possible to deblend scenes that have observations with different instruments that have different resolutions and/or observations that have not been coadded, however that is outside the scope of this tutorial and the interested reader should be referred to https://fred3m.github.io/scarlet/tutorials/multiresolution.html.\n",
    "\n",
    "So we will create an initial model `Frame` that uses a narrow gaussian PSF and an `Observation` that consists of multiple bands of an HSC coadded image.\n",
    "\n",
    "See https://fred3m.github.io/scarlet/user_docs.html#Frame-and-Observation for more on `Frame`s and `Observation`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PSF image of a narrow gaussian to use as our image PSF\n",
    "model_psf = scarlet.generate_psf_image(scarlet.gaussian, shape=(41, 41), amplitude=1, sigma=.9)\n",
    "model_psf /= model_psf.sum()\n",
    "# Make sure that the observation PSF is normalized (otherwise the scaling in PSF matching might be off)\n",
    "psfs = psfs / psfs.sum(axis=(1, 2))[:, None, None]\n",
    "# Create the initial frame (metadata for the model).\n",
    "# Note that we initialized a PSF with shape (Ny, Nx) but a frame\n",
    "# expects a PSf with shape (bands, Ny, Nx), so we have to\n",
    "# broadcast the model_psf into an extra dimension\n",
    "frame = scarlet.Frame(images.shape, psfs=model_psf[None])\n",
    "# Create our observation\n",
    "observation = scarlet.Observation(images, psfs=psfs).match(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Sources\n",
    "\n",
    "Astrophysical objects are modeled in scarlet as a collection of components, where each component has a single SED that is constant over it's morphology (band independent intensity). So a single source might have multiple components, like a bulge and disk, or a single component.\n",
    "\n",
    "The different classes that inherit from `Source` mainly differ in how they are initialized, and otherwise behave similarly during the optimization routine. This section illustrates the differences between different source initialization classes.\n",
    "\n",
    "The simplest source is a single component intialized with only a single pixel (at the center of the object) turned on.\n",
    "\n",
    "### <span style=\"color:red\"> *WARNING* </span>\n",
    "Scarlet accepts source positions using the numpy/C++ convention of (y,x), which is different than the astropy and LSST stack convention of (x,y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [scarlet.PointSource(frame, (peak[1], peak[0]), observation) for peak in peaks]\n",
    "\n",
    "# Display the initial guess for each source\n",
    "display_sources(sources, observation, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "* Experiment with the above code by using `ExtendedSource`, which initializes each object as a single component with maximum flux at the peak that falls off monotonically and has 180 degree symmetry; and using `MultiComponentSource`, which models a source as two components (a bulge and a disk) that are each symmetric and montonically decreasing from the peak.\n",
    "\n",
    "# Deblending a scene\n",
    "\n",
    "The `Blend` class contains the list of sources, the observation(s), and any other configuration parameters necessary to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can fit a model, given a maximum number of iterations and the relative error required for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data until the relative error is <= 1e-3,\n",
    "# for a maximum of 100 iterations\n",
    "blend.fit(100, e_rel=1e-3)\n",
    "print(\"Deblending completed in {0} iterations\".format(blend.it))\n",
    "display_model_residual(images, blend, peaks, norm)\n",
    "display_sources(sources, observation, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Experiment by running the above code using different source models (for example `ExtendedSource`) to see how initializtion affects the belnding results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Functions\n",
    "\n",
    "The above models used the default constraints: perfect symmetry and a weighted monotonicity that decreases from the peak. So each source is created with the update function, equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet import measurement, update\n",
    "\n",
    "class MySource(scarlet.ExtendedSource):\n",
    "    def update(self):\n",
    "        \"\"\"Default update parameters for a PointSource\n",
    "        This method can be overwritten if a different set of constraints\n",
    "        or update functions is desired.\n",
    "        \"\"\"\n",
    "        # Keep track of the iteration so we can skip certain updates\n",
    "        # based on the iteration number\n",
    "        if self._parent is None:\n",
    "            it = 0\n",
    "        else:\n",
    "            it = self._parent.it\n",
    "\n",
    "        # Update the central pixel location (pixel_center)\n",
    "        self.pixel_center = measurement.max_pixel(self.morph, self.pixel_center)\n",
    "\n",
    "        if self.symmetric:\n",
    "            # Update the centroid position every 5th iteration\n",
    "            if it % 5 == 0:\n",
    "                self.pixel_center, self.shift = measurement.psf_weighted_centroid(self.morph,\n",
    "                                                                                  self._centroid_weight,\n",
    "                                                                                  self.pixel_center)\n",
    "\n",
    "            # make the morphology perfectly symmetric\n",
    "            update.symmetric(self, algorithm=\"kspace\")\n",
    "\n",
    "        if self.monotonic:\n",
    "            # make the morphology monotonically decreasing\n",
    "            update.monotonic(self, self.pixel_center)\n",
    "\n",
    "        update.positive(self)  # Make the SED and morph non-negative\n",
    "        update.normalized(self)  # Use MORPH_MAX normalization\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In the code above modify the `MySource.update` method to use different constraints and run the code block following this cell for the following:\n",
    "\n",
    "* Add the keyword argument `use_nearest=True` to `update.monotonic` and see how that affects the results.\n",
    "\n",
    "*  Comment out the lines that set `self.pixel_center` so that positions are not updated and see how that changes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.random.rand(len(peaks), 2)/2\n",
    "sources = [MySource(frame, (peak[1]+offset[k][0], peak[0]+offset[k][1]), observation, bg_rms) for k, peak in enumerate(peaks)]\n",
    "blend = scarlet.Blend(sources, observation)\n",
    "blend.fit(100, e_rel=1e-3)\n",
    "print(\"Deblending completed in {0} iterations\".format(blend.it))\n",
    "display_model_residual(images, blend, peaks, norm)\n",
    "display_sources(sources, observation, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "\n",
    "* Modify `MySource` to create a source that has multiple components. You might want to take a look at [MultiComponentSource](https://github.com/fred3m/scarlet/blob/master/scarlet/source.py#L478) to get an understanding about how to do this, but try your own initialization function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
