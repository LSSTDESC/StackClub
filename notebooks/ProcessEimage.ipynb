{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Exposure Processing\n",
    "\n",
    "This is intended to walk you through the processing pipeline on jupyterlab. It builds on the first two hands-on tutorials in the LSST [\"Getting started\" tutorial series](https://pipelines.lsst.io/getting-started/index.html#getting-started-tutorial). It is intended for anyone getting started with using the LSST Science Pipelines for data processing. \n",
    "\n",
    "The goal of this tutorial is to setup a Butler for a simulated LSST data set and to run the `processCCD.py` pipeline task to produced reduced images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the data repository\n",
    "\n",
    "Sample data for this tutorial comes from the `twinkles` LSST simulation and is available in a shared directory on `jupyterlab`. We will make a copy of the input data in our current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!if [ ! -d DATA ]; then cp -r /project/shared/data/Twinkles_subset/input_data_v2 DATA; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the data directory you'll see a directory structure that looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44K\n",
      "-rw-r--r--  1 kadrlica kadrlica   31 May 10 18:18 _mapper\n",
      "drwxr-xr-x  2 kadrlica kadrlica 4.0K May 10 18:18 config\n",
      "drwxr-xr-x 62 kadrlica kadrlica 4.0K May 10 18:18 eimage\n",
      "drwxr-xr-x  3 kadrlica kadrlica 4.0K May 10 18:18 ref_cats\n",
      "-rw-r--r--  1 kadrlica kadrlica  24K May 10 18:18 registry.sqlite3\n",
      "drwxr-xr-x  3 kadrlica kadrlica 4.0K May 11 06:31 rerun\n"
     ]
    }
   ],
   "source": [
    "!ls -lh DATA/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Butler uses a mapper to find and organize data in a format specific to each camera. Here we're using `lsst.obs.lsstSim.LsstSimMapper` mapper for the Twinkles simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsst.obs.lsstSim.LsstSimMapper\n"
     ]
    }
   ],
   "source": [
    "cat DATA/_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the relavent images and calibrations have already been ingested into the Butler for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing what data will be processed\n",
    "\n",
    "We'll now process individual raw LSST simulated images in the Butler `DATA` repository into calibrated exposures. Weâ€™ll use the `processCcd.py` command-line task to remove instrumental signatures with dark, bias and flat field calibration images. `processCcd.py` will also use the reference catalog to establish a preliminary WCS and photometric zeropoint solution.\n",
    "\n",
    "First we'll examine the set of exposures available in the Twinkles data set using the Butler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do a similar thing using the `processEimageTask` from the LSST pipeline. **There is a bit of ugliness here because the `processEimage.py` command line script is only python2 compatible so we need to parse the arguments through the API. This has the nasty habit of trying to exit after the args.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.obs.lsstSim.processEimage import ProcessEimageTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id dataRef.dataId = {'filter': 'r', 'visit': 230, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 231, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 232, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 233, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 234, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 235, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 236, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 237, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 238, 'raft': '2,2', 'sensor': '1,1'}\n",
      "id dataRef.dataId = {'filter': 'r', 'visit': 239, 'raft': '2,2', 'sensor': '1,1'}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/lsst/software/stack/python/miniconda3-4.3.21/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args = 'DATA --rerun process-eimage  --id filter=r --show data'\n",
    "ProcessEimageTask.parseAndRun(args=args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important arguments here are `--id` and `--show data`.\n",
    "\n",
    "The `--id` argument allows you to select datasets to process by their data IDs. Data IDs describe individual datasets in the Butler repository. Datasets also have types, and each command-line task will only process data of certain types. In this case, `processEimage.py` will processes raw simulated e-images **(need more description of e-images)**.\n",
    "\n",
    "In the above command, the `--id filter=r` argument selects data from the r filter. Specifying `--id` without any arguments acts as a wildcard that selects all raw-type data in the repository.\n",
    "\n",
    "The `--show data` argument puts `processEimage.py` into a dry-run mode that prints a list of data IDs to standard output that would be processed according to the `--id` argument rather than actually processing the data. \n",
    "\n",
    "Notice the keys that describe each data ID, such as the visit (exposure identifier), raft (identifies a specific LSST camera raft), sensor (identifies an individual ccd on a raft) and filter, among others. With these keys you can select exactly what data you want to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform the same task directly with the Butler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.persistence as dafPersist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(230, '2,2', '1,1', 'r'),\n",
       " (231, '2,2', '1,1', 'r'),\n",
       " (232, '2,2', '1,1', 'r'),\n",
       " (233, '2,2', '1,1', 'r'),\n",
       " (234, '2,2', '1,1', 'r'),\n",
       " (235, '2,2', '1,1', 'r'),\n",
       " (236, '2,2', '1,1', 'r'),\n",
       " (237, '2,2', '1,1', 'r'),\n",
       " (238, '2,2', '1,1', 'r'),\n",
       " (239, '2,2', '1,1', 'r')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "butler = dafPersist.Butler(inputs='DATA')\n",
    "butler.queryMetadata('eimage', ['visit', 'raft', 'sensor','filter'], dataId={'filter': 'r'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data\n",
    "\n",
    "Now we'll move on to actually process some of the Twinkles data. To do this, we'll remove the `--show data` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = 'DATA --rerun process-eimage  --id filter=r --show data'\n",
    "ProcessEimageTask.parseAndRun(args=args.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST_Stack (Python 3)",
   "language": "python",
   "name": "lsst_stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
